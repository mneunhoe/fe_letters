mutate(t= time_window[1] - days_to_election +1 ) %>% # create t variable from 1:366
arrange(desc(days_to_election)) %>% # Arrange according to days to election
mutate(iid = match(institute , sort(unique(institute)))) %>% # Creat Institute id
spread(party, support)  %>% # Reshape to wide format
na.omit() # Omit missing
Y <- round(as.matrix(polls[,party_names]/100) *
polls$sample_size) # Grep existing Parties and transform share to number
NObs <- apply(Y,1,sum) # Number of obserations
nParties <-ncol(Y) # Number of parties
forJags <- list(y = Y,
nParties = nParties,
nPeriods =  time_window[1]+1,
nPolls = nrow(Y),
iid = polls$iid,
nInst = max(polls$iid),
date = polls$t,
size = NObs,
beta_priors = beta_priors[party_names,] # Order priors
)
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
update(jags.mod,nBurn)
res_brw <- coda.samples(jags.mod,
n.iter=nIter,thin=nThin,
variable.names=save_var)
draws_forcast_levels <- list() # Output Object
levels <- array(NA,c(nChains*nIter/nThin,nParties,366))
for(t in 1:366){
sel_levels_temp <- paste("alpha[",t,",",1:nParties,"]",sep="")
levels[,,t] <- as.matrix(res_brw[,sel_levels_temp])
}
draws_forcast_levels[["levels"]] <- levels
sel_forcast <- paste("forcast[",1:nParties,"]",sep="")
draws_forcast_levels[["forcast"]] <- as.matrix(res_brw[,sel_forcast])
draws_forcast_levels[["party_names"]] <- party_names
draws_forcast_levels[["polls"]] <- polls
draws_forcast_levels[["forcast"]]
apply(draws_forcast_levels[["forcast"]],2, mean)
runif(10,0,2)
alphastar <- as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, runif(10,0,2)), nrow = nsim)
alphastar <- as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, runif(7*nsim,0,2)), nrow = nsim)
runif(7*nsim,0,2)
mean(matrix(rnorm(7*nsim, 0, 0.1))
ea <- exp(alphastar)
sumea <- apply(ea, 1, sum)
backmean <- apply(ea, 2, mean)/mean(sumea)
backmean
apply(draws_forcast_levels[["forcast"]],2, mean)
mean(matrix(rnorm(7*nsim, 0, 0.1)))
mean(matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim))
mean(matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim))
mean(matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim))
library(MASS)
getALR <- function(x, ref = length(x)){
out <- log(x[-ref]/x[ref])
return(out)
}
getGAL <- function(x){
out <- c(exp(x),1)/sum(c(exp(x), 1))
return(out)
}
rdirichlet <- function(
N = 100,  # Numer of random draws
alpha    # alpha Paramter
){
# One random draw from Dirichlet
rd <- function(a) { y <- rgamma(length(a), a, 1); y / sum(y) }
# Replicate N times
draws <- t(replicate(N, rd(alpha), simplify = TRUE))
# Return draws
return(draws)
}
getarcsin <- function(x){
2*asin(sqrt(x))
}
getinvarsin <- function(x){
(sin(x/2))^2
}
smpl <- function(i,t=100, v=0.00001, K=5){
p <- NULL
p <- rdirichlet(1,sample(1:1000,K))
pk <- getALR(p) + t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
pgal <- getGAL(pk)
pgal - p
}
res <- t(sapply(1:10000,smpl,t=30,v=0.1))
res
apply(res,2,mean)
v=0.1
t=30
K=5
v*diag(rep(1,K-1))
t*mvrnorm(1,rep(0,K-1)
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
rdirichlet(1,sample(1:1000,K))
p <- rdirichlet(1,sample(1:1000,K))
getALR(p)
pgal - p
smpl <- function(i,t=100, v=0.00001, K=5){
p <- NULL
p <- rdirichlet(1,sample(1:1000,K))
pk <- getALR(p) + t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
pgal <- getGAL(pk)
pgal - p
}
t(sapply(1:10000,smpl,t=30,v=0.1))
smpl <- function(i,t=100, v=0.00001, K=5){
p <- NULL
p <<- rdirichlet(1,sample(1:1000,K))
pk <- getALR(p) + t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
pgal <<- getGAL(pk)
pgal - p
}
res <- t(sapply(1:10000,smpl,t=30,v=0.1))
pgal
p
pgal
smpl <- function(i,t=100, v=0.00001, K=5){
p <- NULL
p <<- rdirichlet(1,sample(1:1000,K))
pk <<- getALR(p) + t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
pgal <<- getGAL(pk)
pgal - p
}
res <- t(sapply(1:10000,smpl,t=30,v=0.1))
apply(res,2,mean)
pgal
pgal
pgal
pgal
pgal
pgal
p <<- rdirichlet(1,sample(1:1000,K))
pk <<- getALR(p) + t*mvrnorm(1,rep(0,K-1),v*diag(rep(1,K-1)))
pk
alphastar <- as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
alphastar <- as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
s.matrix(res_brw)[,8:14]
as.matrix(res_brw)[,8:14]
matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
as.matrix(res_brw)[,8:14]
logb <- logb + matrix(rnorm(7*nsim, 0, 1), nrow = nsim)
logb[,nrow(beta_priors)] <- 0
ea <- exp(logb)
sumea <- apply(ea, 1, sum)
backmean <- apply(ea, 2, mean)/mean(sumea)
backmean
logb <- matrix(NA, nrow = nsim, ncol = nrow(beta_priors))
for(i in 1:nrow(beta_priors)){
logb[,i] <- log(rbeta(nsim,beta_priors[i,1],beta_priors[i,2])/rbeta(nsim,beta_priors[7,1],beta_priors[7,2]))
}
logb
logb <- logb + matrix(rnorm(7*nsim, 0, 1), nrow = nsim)
ea <- exp(logb)
sumea <- apply(ea, 1, sum)
backmean <- apply(ea, 2, mean)/mean(sumea)
backmean
logb <- matrix(NA, nrow = nsim, ncol = nrow(beta_priors))
for(i in 1:nrow(beta_priors)){
logb[,i] <- log(rbeta(nsim,beta_priors[i,1],beta_priors[i,2])/rbeta(nsim,beta_priors[7,1],beta_priors[7,2]))
}
logb
logb <- matrix(NA, nrow = nsim, ncol = nrow(beta_priors))
for(i in 1:nrow(beta_priors)){
logb[,i] <- log(rbeta(nsim,beta_priors[i,1],beta_priors[i,2])/rbeta(nsim,beta_priors[7,1],beta_priors[7,2]))
}
apply(logb,2, mean)
logb <- logb + matrix(rnorm(7*nsim, 0, 1), nrow = nsim)
logb[,nrow(beta_priors)] <- 0
logb
ea <- exp(logb)
sumea <- apply(ea, 1, sum)
backmean <- apply(ea, 2, mean)/mean(sumea)
backmean
beta_priors
logb <- matrix(NA, nrow = nsim, ncol = nrow(beta_priors))
for(i in 1:nrow(beta_priors)){
logb[,i] <- log(rbeta(nsim,beta_priors[i,1],beta_priors[i,2])/rbeta(nsim,beta_priors[7,1],beta_priors[7,2]))
}
jags.mod <- jags.model(file = "logratiosampler.jags",
data=forJags,
n.chains=nChains,
n.adapt=1000)
update(jags.mod,nBurn)
res_brw <- coda.samples(jags.mod,
n.iter=nIter,thin=nThin,
variable.names=c("alpha", "alphastar"))
res_brw
nsim <- 100000
nBurn = 100000; nThin=1; nIter=nsim/nChains; nChains=2
jags.mod <- jags.model(file = "logratiosampler.jags",
data=forJags,
n.chains=nChains,
n.adapt=1000)
update(jags.mod,nBurn)
res_brw <- coda.samples(jags.mod,
n.iter=nIter,thin=nThin,
variable.names=c("alpha", "alphastar"))
res_brw
alphastar <- as.matrix(res_brw)[,8:14] + matrix(rnorm(7*nsim, 0, 0.1), nrow = nsim)
alphastar
ea <- exp(alphastar)
sumea <- apply(ea, 1, sum)
backmean <- apply(ea, 2, mean)/mean(sumea)
sum(backmean)
nBurn = 10000; nThin=200; nIter=20000; nChains=2
model_file="polling-model-02-brw-forecast_shock.jags"
save_var=c("alpha","s","house_effect","forcast")
ger_polls <- read_dta("../Data/Polls/polls_btw.dta") %>%
filter(election==Election) %>% # Filter Polls for Election
mutate(party = as.character(as_factor(party)))
load("structural_forecasts.RData") # Load Structural Forcasts
structural_forcasts <- jags_oospreds_summary_df[jags_oospreds_summary_df$election==Election,]
beta_priors <- t(apply(structural_forcasts[,c("mean","sd")]/100,1, function(x) estBetaParams(x[1],x[2]^2)))
rownames(beta_priors) <- structural_forcasts$party
cutoff <- min(ger_polls$days_to_election,na.rm = T)
cat("\n Estimating Model for Election", Election, "with a cutoff of ", cutoff, "\n")
max_days_to_election <- 365 # Start point up from which Polls are included
time_window <- max_days_to_election:cutoff  # time window
party_names <- c("spd","lin","gru","fdp","afd","oth", "cdu") # TRY CDU AS REFERENCE
polls <- ger_polls %>%
filter(days_to_election %in% time_window) %>% # Filter Polls in time-window
select(party, support, days_to_election, sample_size, institute) %>% # Select important information
mutate(t= time_window[1] - days_to_election +1 ) %>% # create t variable from 1:366
arrange(desc(days_to_election)) %>% # Arrange according to days to election
mutate(iid = match(institute , sort(unique(institute)))) %>% # Creat Institute id
spread(party, support)  %>% # Reshape to wide format
na.omit() # Omit missing
Y <- round(as.matrix(polls[,party_names]/100) *
polls$sample_size) # Grep existing Parties and transform share to number
NObs <- apply(Y,1,sum) # Number of obserations
nParties <-ncol(Y) # Number of parties
forJags <- list(y = Y,
nParties = nParties,
nPeriods =  time_window[1]+1,
nPolls = nrow(Y),
iid = polls$iid,
nInst = max(polls$iid),
date = polls$t,
size = NObs,
beta_priors = beta_priors[party_names,] # Order priors
)
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
s
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
forJags <- list(y = Y,
nParties = nParties,
nPeriods =  time_window[1]+1,
nPolls = nrow(Y),
iid = polls$iid,
nInst = max(polls$iid),
date = polls$t,
size = NObs,
beta_priors = beta_priors[party_names,] # Order priors
)
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
jags.mod <- jags.model(file = model_file,
data=forJags,
n.chains=nChains,
n.adapt=1000)
update(jags.mod,nBurn)
res_brw <- coda.samples(jags.mod,
n.iter=nIter,thin=nThin,
variable.names=save_var)
draws_forcast_levels <- list() # Output Object
levels <- array(NA,c(nChains*nIter/nThin,nParties,366))
for(t in 1:366){
sel_levels_temp <- paste("alpha[",t,",",1:nParties,"]",sep="")
levels[,,t] <- as.matrix(res_brw[,sel_levels_temp])
}
draws_forcast_levels[["levels"]] <- levels
sel_forcast <- paste("forcast[",1:nParties,"]",sep="")
draws_forcast_levels[["forcast"]] <- as.matrix(res_brw[,sel_forcast])
draws_forcast_levels[["party_names"]] <- party_names
draws_forcast_levels[["polls"]] <- polls
draws_forcast_levels[["forcast"]]
apply(draws_forcast_levels[["forcast"]],1,sum)
apply(draws_forcast_levels[["forcast"]],2,mean)
list.of.packages <- c("rstudioapi","blockTools", "nbpMatching","dplyr", "plyr","sp","rgdal","RColorBrewer","ri","parallel","experiment")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies = T)
sapply(list.of.packages, require, character.only = TRUE)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
source("functions/functions.R")
source("functions/FRTCI_function_library.R")
if(!dev.cur()==1) dev.off()
MAKE_PAPER <- FALSE
pre_data <- read.csv2("data/pre_data.csv",stringsAsFactors = F)
sample_data <- pre_data[which(pre_data$eligible_voters_2011<=1500),]
rest_data <-  pre_data[-which(pre_data$eligible_voters_2011<=1500),]
sample_block <- block(sample_data, groups = "electoral_district", n.tr = 2, id.vars = c("community_long_ID")
, block.vars = c("eligible_voters_2011", "turnout_2011","green_percent_2011","proportion_male","proportion_german","proportion_under18","proportion_18to64","proportion_over65")
, algorithm="optGreedy"
, distance = "mahalanobis"
, level.two = FALSE, verbose = TRUE)
sample_assignment <- assignment(sample_block,seed=100290)
dir.create(paste(getwd(),"/assignment_files",sep=""))
setwd(paste(getwd(),"/assignment_files",sep=""))
outCSV(sample_assignment)
files <-  list.files(pattern="Group")
assignment_list <-   do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
assignment_list <- assignment_list[order(assignment_list$Distance) , ]
assigned.distr1 <- rep(NA,length(assignment_list$Treatment.1))
assigned.distr2 <- rep(NA,length(assignment_list$Treatment.2))
suppressWarnings(
for (i in 1:length(assignment_list$Treatment.1)){
assigned.distr1[i] <- sample_data$electoral_district[sample_data$community_long_ID==assignment_list$Treatment.1[i]]
}
)
suppressWarnings(
for (i in 1:length(assignment_list$Treatment.2)){
assigned.distr2[i] <- sample_data$electoral_district[sample_data$community_long_ID==assignment_list$Treatment.2[i]]
}
)
assigned.district <- ifelse(is.na(assigned.distr1),assigned.distr2,assigned.distr1 )
assignment_list$electoral_district <- assigned.district
names(assignment_list) <- c("Rank_in_electoral_district","Treatment","Control","Multivariate_Distance","electoral_district")
write.csv(assignment_list,paste(Sys.Date(),"_final_assignment_list.csv",sep=""))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
if ( MAKE_PAPER ) {
dir.create(paste(getwd(),"/graphs",sep=""))
}
gadm <- readRDS("data/DEU_adm4.rds")
bw <- gadm[gadm$NAME_1=="Baden-Württemberg",]
rm(gadm)
bw@data$NAME_4[bw@data$NAME_4=="Widdern"] <- "Widdern, Stadt"
bw@data$NAME_4[bw@data$NAME_4=="Hettingen"] <- "Hettingen, Stadt"
bw@data$NAME_4[bw@data$NAME_4=="Langenburg"] <- "Langenburg, Stadt"
myColours <- rep("white", length(bw@data$NAME_4))
myColours[bw@data$NAME_4%in%sample_data$community_name] <- gray.colors(3)[1]
myColours[64] <- "white" #pick right Altdorf
myColours[116] <- "white" #pick right Altheim
myColours[370] <- "white" #pick right Dürnau
myColours[403] <- "white" #pick right Talheim
if ( MAKE_PAPER ) {
pdf("graphs/map_sample.pdf",width=9, height=8)
}
par(
family = "serif",
oma = c(1,1,1,1),
mar = c(5,5,5,5),
adj = 0.5
)
plot(bw,col = myColours, border = 'gray80')
title("The Location of the 185 small communities \n in Baden-Württemberg")
legend("bottom", inset=c(0,-0.1), legend=c("Community with <= 1,500 eligible voters in 2011","Community with > 1,500  eligible voters in 2011"), fill=c(gray.colors(3)[1],"white"),border="gray80",bty="n",cex=0.8,xpd=TRUE)
if ( MAKE_PAPER ) {
dev.off()
}
plot_data <- read.csv2("data/plot_data.csv",stringsAsFactors = F)
sample <- myColours==gray.colors(3)[1]
trt_map <- which(sample)[bw@data$NAME_4[sample]%in%as.character(plot_data$community_name)[plot_data$treatment_indicator_Z==1]]
con_map <- which(sample)[bw@data$NAME_4[sample]%in%as.character(plot_data$community_name)[plot_data$treatment_indicator_Z==0]]
myColours <- rep("white", length(bw@data$NAME_4))
myColours[trt_map] <- gray.colors(3)[1]
myColours[con_map] <- gray.colors(3)[2]
if ( MAKE_PAPER ) {
pdf("graphs/map_trt_con.pdf",width=9, height=8)
}
par(
family = "serif",
oma = c(1,1,1,1),
mar = c(5,5,5,5),
adj = 0.5
)
plot(bw,col = myColours, border = 'gray80')
title("The Location of the Treatment and Control Communities")
legend("bottom", inset=c(0,-0.1), legend=c("Treatment","Control"), fill=c(gray.colors(3)[1],gray.colors(3)[2]),border="gray80",bty="n",cex=0.8,xpd=TRUE)
if ( MAKE_PAPER ) {
dev.off()
}
assumed.ate <- seq(0.001,0.02,0.002)
n.pairs <- 2:100
power <- vector("list",length(assumed.ate))
names(power) <- paste(assumed.ate)
for(i in 1:length(assumed.ate)){
power[[i]] <- power.function(assumed.ate = assumed.ate[i],var.assumed.diff = 0.001,n.pairs = n.pairs)
names(power[[i]]) <- paste(n.pairs,"pairs")
}
col <- rev(grey.colors(length(power)))
if ( MAKE_PAPER ) {
col <- rep("black",10)
}
if ( MAKE_PAPER ) {
pdf("graphs/power_curves.pdf",width=9, height=8)
}
par(
family = "serif",
oma = c(1,1,1,1),
mar = c(5,5,5,2),
adj = 0.5
)
plot(n.pairs,power[[1]],type="l"
,ylim=c(0,1),col=col[1]
,ylab=expression(paste("Power of the Experiment 1-",beta))
,xlab="Number of Matched Pairs m"
,main=bquote(atop(bold("Power of the Experiment for different hypothetical ATE"),
"and " ~ alpha ~ " = 0.05")))
for(i in 2:length(power)){
lines(n.pairs,power[[i]],col=col[i])
}
abline(h=0.8,lty=2)
abline(v=41,lty=2)
label <- paste("ATE",names(power))
text(75,power[[1]][74]+0.03, label[1],cex = 0.7,col=col[1])
text(70,power[[2]][69]+0.03, label[2],cex = 0.7,col=col[2],srt=8)
text(65,power[[3]][64]+0.03, label[3],cex = 0.7,col=col[3],srt=13)
text(60,power[[4]][59]+0.03, label[4],cex = 0.7,col=col[4],srt=18)
text(55,power[[5]][54]+0.03, label[5],cex = 0.7,col=col[5],srt=23)
text(50,power[[6]][49]+0.03, label[6],cex = 0.7,col=col[6],srt=28)
text(45,power[[7]][44]+0.03, label[7],cex = 0.7,col=col[7],srt=30)
text(40,power[[8]][39]+0.03, label[8],cex = 0.7,col=col[8],srt=32)
text(35,power[[9]][34]+0.03, label[9],cex = 0.7,col=col[9],srt=35)
text(30,power[[10]][29]+0.03, label[10],cex = 0.7,col=col[10],srt=38)
if ( MAKE_PAPER ) {
dev.off()
}
MAKE_PAPER <- TRUE
if ( MAKE_PAPER ) {
dir.create(paste(getwd(),"/graphs",sep=""))
}
assumed.ate <- seq(0.001,0.02,0.002)
n.pairs <- 2:100
power <- vector("list",length(assumed.ate))
names(power) <- paste(assumed.ate)
for(i in 1:length(assumed.ate)){
power[[i]] <- power.function(assumed.ate = assumed.ate[i],var.assumed.diff = 0.001,n.pairs = n.pairs)
names(power[[i]]) <- paste(n.pairs,"pairs")
}
col <- rev(grey.colors(length(power)))
if ( MAKE_PAPER ) {
col <- rep("black",10)
}
if ( MAKE_PAPER ) {
pdf("graphs/power_curves.pdf",width=9, height=8)
}
par(
family = "serif",
oma = c(1,1,1,1),
mar = c(5,5,5,2),
adj = 0.5
)
plot(n.pairs,power[[1]],type="l"
,ylim=c(0,1),col=col[1]
,ylab=expression(paste("Power of the Experiment 1-",beta))
,xlab="Number of Matched Pairs m"
,main=bquote(atop(bold("Power of the Experiment for different hypothetical ATE"),
"and " ~ alpha ~ " = 0.05")))
for(i in 2:length(power)){
lines(n.pairs,power[[i]],col=col[i])
}
abline(h=0.8,lty=2)
abline(v=41,lty=2)
label <- paste("ATE",names(power))
text(75,power[[1]][74]+0.03, label[1],cex = 0.7,col=col[1])
text(70,power[[2]][69]+0.03, label[2],cex = 0.7,col=col[2],srt=8)
text(65,power[[3]][64]+0.03, label[3],cex = 0.7,col=col[3],srt=13)
text(60,power[[4]][59]+0.03, label[4],cex = 0.7,col=col[4],srt=18)
text(55,power[[5]][54]+0.03, label[5],cex = 0.7,col=col[5],srt=23)
text(50,power[[6]][49]+0.03, label[6],cex = 0.7,col=col[6],srt=28)
text(45,power[[7]][44]+0.03, label[7],cex = 0.7,col=col[7],srt=30)
text(40,power[[8]][39]+0.03, label[8],cex = 0.7,col=col[8],srt=32)
text(35,power[[9]][34]+0.03, label[9],cex = 0.7,col=col[9],srt=35)
text(30,power[[10]][29]+0.03, label[10],cex = 0.7,col=col[10],srt=38)
if ( MAKE_PAPER ) {
dev.off()
}
